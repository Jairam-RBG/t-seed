{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "583e3f3d",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2326a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducing results, we kept only the test files in your repos without making any changes\n",
    "# you shall download it through the followig commands\n",
    "\n",
    "# !pip install gdown\n",
    "# !gdown --id 1pyha4gUFtUG-pIS17IVKAm88II3GgknR\n",
    "# tar -xvf LibriAdapt.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d630f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing required libries for evaluation\n",
    "\n",
    "# !pip install librosa\n",
    "# !pip install datasets\n",
    "# !pip install pandas\n",
    "# !pip install jiwer\n",
    "# !pip install progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e211547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from progressbar import progressbar\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b54a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where you untar the downloaded file\n",
    "data_folder = \"/home/ubuntu/speech_data/t-seed/LibriAdapt/en-us\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a72fab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "variation1 = \"rain\" # possbile values (clean, rain, wind, laughter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80b17188",
   "metadata": {},
   "outputs": [],
   "source": [
    "variation2 = \"matrix\" # possbile values (matrix, nexus6, pseye, respeaker, shure, usb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49eee123",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_file = os.path.join(data_folder,  variation2 + \".tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c95a86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(tsv_file, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "024453c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2600, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9379dfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>audios</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8555-292519-0000.wav</td>\n",
       "      <td>brighter than early dawn's most brilliant dye ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8555-292519-0001.wav</td>\n",
       "      <td>guided by you how we might stroll towards deat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8555-292519-0002.wav</td>\n",
       "      <td>venice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                audios  \\\n",
       "0           0  8555-292519-0000.wav   \n",
       "1           1  8555-292519-0001.wav   \n",
       "2           2  8555-292519-0002.wav   \n",
       "\n",
       "                                                text  \n",
       "0  brighter than early dawn's most brilliant dye ...  \n",
       "1  guided by you how we might stroll towards deat...  \n",
       "2                                             venice  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48802cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add full path to the file names in the column data_frame[\"audios\"]\n",
    "\n",
    "data_frame[\"audios\"] = data_frame[\"audios\"].apply(lambda x: os.path.join(\n",
    "    data_folder, variation1, variation2, \"test\", x))\n",
    "\n",
    "\n",
    "# lower case the transcripts in the column data_frame[\"text\"]\n",
    "\n",
    "data_frame[\"text\"] = data_frame[\"text\"].apply(lambda x: x.lower())\n",
    "\n",
    "# removing special characters from the transcripts in the column data_frame[\"text\"]\n",
    "\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�]'\n",
    "\n",
    "def remove_special_characters(sentence):\n",
    "    sentence = re.sub(chars_to_ignore_regex, '', sentence)\n",
    "    return sentence\n",
    "\n",
    "data_frame[\"text\"] = data_frame[\"text\"].apply(lambda x: remove_special_characters(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c72fc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>audios</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/home/ubuntu/speech_data/t-seed/LibriAdapt/en-...</td>\n",
       "      <td>brighter than early dawn's most brilliant dye ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/home/ubuntu/speech_data/t-seed/LibriAdapt/en-...</td>\n",
       "      <td>guided by you how we might stroll towards deat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>/home/ubuntu/speech_data/t-seed/LibriAdapt/en-...</td>\n",
       "      <td>venice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             audios  \\\n",
       "0           0  /home/ubuntu/speech_data/t-seed/LibriAdapt/en-...   \n",
       "1           1  /home/ubuntu/speech_data/t-seed/LibriAdapt/en-...   \n",
       "2           2  /home/ubuntu/speech_data/t-seed/LibriAdapt/en-...   \n",
       "\n",
       "                                                text  \n",
       "0  brighter than early dawn's most brilliant dye ...  \n",
       "1  guided by you how we might stroll towards deat...  \n",
       "2                                             venice  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f4aea22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/speech_data/t-seed/LibriAdapt/en-us/rain/matrix/test/8555-292519-0001.wav\n"
     ]
    }
   ],
   "source": [
    "# viewing path of a single file\n",
    "# \"/home/ubuntu/speech_data/t-seed/LibriSpeech/\" will be path where you untar the downloaded file\n",
    "print(data_frame[\"audios\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "720f5618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22050\n"
     ]
    }
   ],
   "source": [
    "# check one file from the data_frame for specifications\n",
    "audio_array, sampling_rate = librosa.load(data_frame[\"audios\"][1])\n",
    "\n",
    "print(sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f40de287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "# resampling audio file to 16 KHz\n",
    "\n",
    "audio_array, sampling_rate = librosa.load(data_frame[\"audios\"][1], sr=16000)\n",
    "print(sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69a218b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7991\n"
     ]
    }
   ],
   "source": [
    "# getting unique words in the transcripts to use it with the language modeler\n",
    "\n",
    "words = \" \".join(list(data_frame[\"text\"])).split()\n",
    "unique_words = list(set(words))\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f23ff0d",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c060ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell to be removed\n",
    "import config\n",
    "import torch\n",
    "import torchaudio\n",
    "from common.transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from stack.VoiceTranscriber import VoiceDecoder\n",
    "from stack.VoiceEnhancer import Enhancer\n",
    "\n",
    "from demucs import pretrained\n",
    "from demucs.apply import apply_model\n",
    "from demucs.audio import AudioFile, convert_audio, save_audio\n",
    "\n",
    "def load_track(track, device, audio_channels, samplerate):\n",
    "    errors = {}\n",
    "    wav = None\n",
    "\n",
    "    try:\n",
    "        wav = AudioFile(track).read(\n",
    "            streams=0,\n",
    "            samplerate=samplerate,\n",
    "            channels=audio_channels).to(device)\n",
    "    except FileNotFoundError:\n",
    "        errors['ffmpeg'] = 'Ffmpeg is not installed.'\n",
    "    except subprocess.CalledProcessError:\n",
    "        errors['ffmpeg'] = 'FFmpeg could not read the file.'\n",
    "\n",
    "    if wav is None:\n",
    "        try:\n",
    "            wav, sr = ta.load(str(track))\n",
    "        except RuntimeError as err:\n",
    "            errors['torchaudio'] = err.args[0]\n",
    "        else:\n",
    "            wav = wav.to(device)\n",
    "            wav = convert_audio(wav, sr, samplerate, audio_channels)\n",
    "\n",
    "    if wav is None:\n",
    "        print(f\"Could not load file {track}. \"\n",
    "              \"Maybe it is not a supported file format? \")\n",
    "        for backend, error in errors.items():\n",
    "            print(f\"When trying to load using {backend}, got the following error: {error}\")\n",
    "        sys.exit(1)\n",
    "    return wav\n",
    "\n",
    "def make_batch(wav_tensor, batch_size = 10):\n",
    "    pad_value = batch_size - wav_tensor.shape[1] % batch_size\n",
    "    pad_tensor = torch.zeros(wav_tensor.shape[0], pad_value)\n",
    "    wav_tensor = torch.cat((wav_tensor, pad_tensor), 1)\n",
    "    frame_size = int(wav_tensor.shape[1] / batch_size)\n",
    "    for i in range (0,batch_size):\n",
    "        if i == 0:\n",
    "            temp_tensor = wav_tensor[:, i*frame_size:(i*frame_size)+frame_size]\n",
    "            final_tensor = temp_tensor.unsqueeze(0)\n",
    "        else:\n",
    "            temp_tensor = wav_tensor[:, i*frame_size:(i*frame_size)+frame_size].unsqueeze(0)\n",
    "            final_tensor = torch.cat((final_tensor, temp_tensor), 0)\n",
    "    return final_tensor\n",
    "\n",
    "def destroy_batch(batch_out, index):\n",
    "    if index == None:\n",
    "        for i in range(0, batch_out.shape[0]):\n",
    "            if i == 0:\n",
    "                temp_out = batch_out[i]\n",
    "                final_out = temp_out\n",
    "            else:\n",
    "                temp_out = batch_out[i]\n",
    "                final_out = torch.cat((final_out, temp_out), 1)\n",
    "    else:\n",
    "        for i in range(0, batch_out.shape[0]):\n",
    "            if i == 0:\n",
    "                temp_out = batch_out[i][index]\n",
    "                final_out = temp_out\n",
    "            else:\n",
    "                temp_out = batch_out[i][index]\n",
    "                final_out = torch.cat((final_out, temp_out), 1)\n",
    "    return final_out\n",
    "\n",
    "\n",
    "def get_batch_size(temp_wav):\n",
    "    size = int(temp_wav.shape[1]/250000)\n",
    "\n",
    "    if size == 0:\n",
    "        b_size = 1\n",
    "    elif size <= 4:\n",
    "        b_size = 2\n",
    "    elif size <= 7:\n",
    "        b_size = 5\n",
    "    elif size <= 12:\n",
    "        b_size = 10\n",
    "    elif size <= 17:\n",
    "        b_size = 15\n",
    "    elif size <= 22:\n",
    "        b_size = 20\n",
    "    elif size <= 27:\n",
    "        b_size = 25\n",
    "    else:\n",
    "        b_size = 30\n",
    "    return b_size\n",
    "\n",
    "\n",
    "# model = pretrained.get_model('mdx')\n",
    "# voice_separation_model = model.models[3]\n",
    "# voice_separation_model = voice_separation_model.to(\"cuda\")\n",
    "\n",
    "transcriber_processor = Wav2Vec2Processor.from_pretrained(config.encoder_path)\n",
    "transcriber_processor.tokenizer.do_lower_case = True\n",
    "transcriber_encoder_model = Wav2Vec2ForCTC.from_pretrained(config.encoder_path)\n",
    "\n",
    "lex_words = [word for word in unique_words if len(word.strip())>0]\n",
    "\n",
    "temp_lexicon = \"temp_lex.txt\"\n",
    "with open(temp_lexicon, \"w+\") as f:\n",
    "    for word in lex_words:\n",
    "        chars = [c for c in word]\n",
    "        w_word = [word] + chars + [\"|\"]\n",
    "        f.write(\" \".join(w_word) + \"\\n\")\n",
    "\n",
    "transcriber_decoder_model = VoiceDecoder(transcriber_processor,\n",
    "                                         config.decoder_path,\n",
    "                                         temp_lexicon, lexicon_option=True)\n",
    "transcriber_encoder_model  = transcriber_encoder_model.to(\"cuda\")\n",
    "\n",
    "noise_remover_model = Enhancer()\n",
    "state_dict = torch.load(config.enhancer_path,\n",
    "                        map_location=torch.device(\"cuda:0\"))\n",
    "noise_remover_model.load_state_dict(state_dict)\n",
    "noise_remover_model = noise_remover_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae26d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.samplerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cedfb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction against base model with and without language modeler\n",
    "\n",
    "def get_transcriptions(audio_path, unique_words, e_type=\"base_model\"):\n",
    "    \n",
    "    \n",
    "#     raw_wav = load_track(audio_path, \"cpu\", model.audio_channels, 44100)\n",
    "\n",
    "#     batch_size = get_batch_size(raw_wav)\n",
    "#     batch_wav = make_batch(raw_wav, batch_size=batch_size)\n",
    "\n",
    "#     for i, item in enumerate(batch_wav):\n",
    "#         item = item.unsqueeze(0)\n",
    "#         with torch.no_grad():\n",
    "#             item = item.to(\"cuda\")\n",
    "#             output = voice_separation_model(item)\n",
    "#             item = item.to(\"cpu\")\n",
    "#             if i == 0:\n",
    "#                 batch_output = output.to(\"cpu\")\n",
    "#             else:\n",
    "#                 batch_output = torch.cat((batch_output, output.to(\"cpu\")))\n",
    "                \n",
    "#     vs_wav = destroy_batch(batch_output, index=3)\n",
    "    \n",
    "#     torchaudio.save(\"temp.wav\", vs_wav, 44100)\n",
    "    \n",
    "    audio_array, sampling_rate = librosa.load(audio_path, sr=16000)\n",
    "    \n",
    "    audio_array = torch.tensor(audio_array)\n",
    "    \n",
    "    audio_array = audio_array.to(\"cuda\").unsqueeze(0)\n",
    "    output = noise_remover_model(audio_array)\n",
    "    \n",
    "    \n",
    "    dry = 0.7\n",
    "    output = (1 - dry) * output + dry * audio_array\n",
    "    \n",
    "    wav = output / max(output.abs().max().item(), 1)\n",
    "    \n",
    "    wav = wav.squeeze(0).squeeze(0)\n",
    "#     audio_array = audio_array.to(\"cpu\")\n",
    "    \n",
    "    inputs = transcriber_processor(wav, sampling_rate=sampling_rate,\n",
    "                                       return_tensors=\"pt\", padding=True)\n",
    "    inputs = inputs.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "            character_probability = transcriber_encoder_model(inputs.input_values,\n",
    "                                                              attention_mask=inputs.attention_mask).logits\n",
    "    inputs = inputs.to(\"cpu\")\n",
    "    predicted_ids = torch.argmax(character_probability, dim=-1)\n",
    "    encoder_text = transcriber_processor.batch_decode(predicted_ids)[0]\n",
    "    character_probability = torch.nn.functional.log_softmax(character_probability.float(), dim=-1)\n",
    "\n",
    "    character_probability  =  character_probability.to(\"cpu\")\n",
    "    lm_tokens, lm_scores = transcriber_decoder_model.decode(character_probability)\n",
    "    prediction_ids = lm_tokens[0][:]\n",
    "    decoder_text = transcriber_processor.batch_decode(prediction_ids)[0]\n",
    "    \n",
    "    return encoder_text, decoder_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cde909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 2600) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--/home/ubuntu/AISS/common/transformers/feature_extraction_utils.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  tensor = as_tensor(value)\n",
      "/home/ubuntu/AISS/common/transformers/models/wav2vec2/modeling_wav2vec2.py:875: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return (input_length - kernel_size) // stride + 1\n",
      " 31% (829 of 2600) |######               | Elapsed Time: 0:20:14 ETA:   0:37:19"
     ]
    }
   ],
   "source": [
    "without_lm_op = list()\n",
    "with_lm_op = list()\n",
    "e_type = \"enhanced\"\n",
    "for item in progressbar(data_frame[\"audios\"]):\n",
    "    e_text, d_text = get_transcriptions(item, unique_words, e_type=e_type)\n",
    "    without_lm_op.append(e_text)\n",
    "    with_lm_op.append(d_text)\n",
    "\n",
    "data_frame[\"without_lm\"] = without_lm_op\n",
    "data_frame[\"with_lm\"] = with_lm_op\n",
    "data_frame.to_csv(\"results/LibriAdapt-\"+ variation1 +\"-\"+ variation2 + \"-\" + e_type + \".tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8242e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cae54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = load_metric(\"wer\")\n",
    "without_lm_wer = wer_metric.compute(predictions=data_frame[\"without_lm\"], references=data_frame[\"text\"])\n",
    "with_lm_wer = wer_metric.compute(predictions=data_frame[\"with_lm\"], references=data_frame[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc524b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09664169616836506"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_lm_wer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f520993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06065288399475815"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_lm_wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba16bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7735bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiss",
   "language": "python",
   "name": "aiss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
